{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport string\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n!pip install seaborn\nimport seaborn as sns\n\nimport tensorflow as tf\n!pip install transformers shap lime\n\nimport transformers\nfrom transformers import BertTokenizer\nfrom transformers import TFAutoModel\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nprint(tf.__version__)\nprint(transformers.__version__)","metadata":{"id":"4LgdBJlMt4x6","outputId":"4ffe1042-e63a-4149-ab1f-ac5f9873c301","scrolled":true,"execution":{"iopub.status.busy":"2023-05-16T20:12:09.720467Z","iopub.execute_input":"2023-05-16T20:12:09.721319Z","iopub.status.idle":"2023-05-16T20:13:34.404117Z","shell.execute_reply.started":"2023-05-16T20:12:09.721273Z","shell.execute_reply":"2023-05-16T20:13:34.403246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 📋 Loading the Data","metadata":{"id":"eYjQNqxat4x8"}},{"cell_type":"code","source":"!pip install gensim nltk\nimport pandas as pd\nimport numpy as np\nimport gensim\nfrom gensim.models import Word2Vec\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndf = pd.read_csv('/kaggle/input/uk-twitter-covid19-dataset/sample_data_all.csv')\n#df = pd.read_csv('/kaggle/input/extended-covid-twitter-datasets/sample_data_global.csv')\n#df = pd.read_csv('/kaggle/input/external-covid-19-twitter-dataset/Reddit_Data.csv')\n#df = pd.read_csv('/kaggle/input/external-covid-19-twitter-dataset/Twitter_Data.csv')","metadata":{"id":"9Oxb2ZWNt4x9","outputId":"616641b9-3be7-47c5-dfdd-b2be43c70014","scrolled":true,"execution":{"iopub.status.busy":"2023-05-16T20:13:34.406254Z","iopub.execute_input":"2023-05-16T20:13:34.407103Z","iopub.status.idle":"2023-05-16T20:13:44.549759Z","shell.execute_reply.started":"2023-05-16T20:13:34.407068Z","shell.execute_reply":"2023-05-16T20:13:44.548791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.info())","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:13:44.550996Z","iopub.execute_input":"2023-05-16T20:13:44.551282Z","iopub.status.idle":"2023-05-16T20:13:44.584832Z","shell.execute_reply.started":"2023-05-16T20:13:44.551258Z","shell.execute_reply":"2023-05-16T20:13:44.583887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text'] = df['clean_tweet']\ndf['target'] = df['senti_textblob']\n#df['text'] = df['clean_comment']\n#df['target'] = df['category']","metadata":{"id":"xvyBg-3xv3lu","execution":{"iopub.status.busy":"2023-05-16T20:13:44.585920Z","iopub.execute_input":"2023-05-16T20:13:44.586270Z","iopub.status.idle":"2023-05-16T20:13:44.597135Z","shell.execute_reply.started":"2023-05-16T20:13:44.586243Z","shell.execute_reply":"2023-05-16T20:13:44.596284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nimport pandas as pd\n\n# assuming your dataframe is named 'df'\nnum_samples_per_label = 2000\n\n# group the dataframe by the label column\ngrouped_df = df.groupby('target')\n\n# sample a specified number of rows from each group\nsampled_df = grouped_df.apply(lambda x: x.sample(n=num_samples_per_label))\n\n# reset the index of the resulting dataframe\nsampled_df = sampled_df.reset_index(drop=True)\ndf = sampled_df \n'''","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:13:44.599601Z","iopub.execute_input":"2023-05-16T20:13:44.599874Z","iopub.status.idle":"2023-05-16T20:13:44.612870Z","shell.execute_reply.started":"2023-05-16T20:13:44.599850Z","shell.execute_reply":"2023-05-16T20:13:44.612072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns = ['clean_tweet','senti_textblob'])\ndf","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:13:44.613884Z","iopub.execute_input":"2023-05-16T20:13:44.614251Z","iopub.status.idle":"2023-05-16T20:13:44.659233Z","shell.execute_reply.started":"2023-05-16T20:13:44.614226Z","shell.execute_reply":"2023-05-16T20:13:44.658478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df[['text','target']], test_size = 0.2, random_state = 42)","metadata":{"id":"jajcwldZt4x-","execution":{"iopub.status.busy":"2023-05-16T20:13:44.660238Z","iopub.execute_input":"2023-05-16T20:13:44.660523Z","iopub.status.idle":"2023-05-16T20:13:44.670082Z","shell.execute_reply.started":"2023-05-16T20:13:44.660498Z","shell.execute_reply":"2023-05-16T20:13:44.669340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:13:44.671129Z","iopub.execute_input":"2023-05-16T20:13:44.671463Z","iopub.status.idle":"2023-05-16T20:13:44.686511Z","shell.execute_reply.started":"2023-05-16T20:13:44.671418Z","shell.execute_reply":"2023-05-16T20:13:44.685622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train, counts of label '1': {}\".format(sum(train.target == 1)))\nprint(\"train, counts of label '0': {}\".format(sum(train.target == 0)))\nprint(\"train, counts of label '-1': {}\\n\".format(sum(train.target == -1)))\nprint(\"test, counts of label '1': {}\".format(sum(test.target == 1)))\nprint(\"test, counts of label '0': {}\".format(sum(test.target == 0)))\nprint(\"test, counts of label '-1': {}\".format(sum(test.target == -1)))","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:13:44.687691Z","iopub.execute_input":"2023-05-16T20:13:44.688122Z","iopub.status.idle":"2023-05-16T20:13:44.713707Z","shell.execute_reply.started":"2023-05-16T20:13:44.688082Z","shell.execute_reply":"2023-05-16T20:13:44.712892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df\n\n#train = reduce_mem_usage(train)\n#train = reduce_mem_usage(test)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:13:44.714702Z","iopub.execute_input":"2023-05-16T20:13:44.715162Z","iopub.status.idle":"2023-05-16T20:13:44.730111Z","shell.execute_reply.started":"2023-05-16T20:13:44.715138Z","shell.execute_reply":"2023-05-16T20:13:44.729406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train2, test2 = train, test","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:13:44.731047Z","iopub.execute_input":"2023-05-16T20:13:44.731342Z","iopub.status.idle":"2023-05-16T20:13:44.746487Z","shell.execute_reply.started":"2023-05-16T20:13:44.731319Z","shell.execute_reply":"2023-05-16T20:13:44.745602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🔨 Preprocessing","metadata":{"id":"-vJVSjfLt4x_"}},{"cell_type":"code","source":"#Use regex to clean the data\ndef remove_url(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\ndef remove_punct(text):\n    table = str.maketrans('', '', string.punctuation)\n    return text.translate(table)\ndef remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\ndef decontraction(text):\n    text = re.sub(r\"won\\'t\", \" will not\", text)\n    text = re.sub(r\"won\\'t've\", \" will not have\", text)\n    text = re.sub(r\"can\\'t\", \" can not\", text)\n    text = re.sub(r\"don\\'t\", \" do not\", text)\n    \n    text = re.sub(r\"can\\'t've\", \" can not have\", text)\n    text = re.sub(r\"ma\\'am\", \" madam\", text)\n    text = re.sub(r\"let\\'s\", \" let us\", text)\n    text = re.sub(r\"ain\\'t\", \" am not\", text)\n    text = re.sub(r\"shan\\'t\", \" shall not\", text)\n    text = re.sub(r\"sha\\n't\", \" shall not\", text)\n    text = re.sub(r\"o\\'clock\", \" of the clock\", text)\n    text = re.sub(r\"y\\'all\", \" you all\", text)\n\n    text = re.sub(r\"n\\'t\", \" not\", text)\n    text = re.sub(r\"n\\'t've\", \" not have\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"\\'s\", \" is\", text)\n    text = re.sub(r\"\\'d\", \" would\", text)\n    text = re.sub(r\"\\'d've\", \" would have\", text)\n    text = re.sub(r\"\\'ll\", \" will\", text)\n    text = re.sub(r\"\\'ll've\", \" will have\", text)\n    text = re.sub(r\"\\'t\", \" not\", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    text = re.sub(r\"\\'m\", \" am\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    return text \n\ndef seperate_alphanumeric(text):\n    words = text\n    words = re.findall(r\"[^\\W\\d_]+|\\d+\", words)\n    return \" \".join(words)\n\ndef cont_rep_char(text):\n    tchr = text.group(0) \n    \n    if len(tchr) > 1:\n        return tchr[0:2] \n\ndef unique_char(rep, text):\n    substitute = re.sub(r'(\\w)\\1+', rep, text)\n    return substitute\n\ntrain['text'] = train['text'].apply(lambda x : remove_url(x))\ntrain['text'] = train['text'].apply(lambda x : remove_punct(x))\ntrain['text'] = train['text'].apply(lambda x : remove_emoji(x))\ntrain['text'] = train['text'].apply(lambda x : decontraction(x))\ntrain['text'] = train['text'].apply(lambda x : seperate_alphanumeric(x))\ntrain['text'] = train['text'].apply(lambda x : unique_char(cont_rep_char,x))\n\ntest['text'] = test['text'].apply(lambda x : remove_url(x))\ntest['text'] = test['text'].apply(lambda x : remove_punct(x))\ntest['text'] = test['text'].apply(lambda x : remove_emoji(x))\ntest['text'] = test['text'].apply(lambda x : decontraction(x))\ntest['text'] = test['text'].apply(lambda x : seperate_alphanumeric(x))\ntest['text'] = test['text'].apply(lambda x : unique_char(cont_rep_char,x))","metadata":{"id":"tGVTdyEst4x_","execution":{"iopub.status.busy":"2023-05-16T20:13:44.747672Z","iopub.execute_input":"2023-05-16T20:13:44.748061Z","iopub.status.idle":"2023-05-16T20:13:48.675831Z","shell.execute_reply.started":"2023-05-16T20:13:44.748035Z","shell.execute_reply":"2023-05-16T20:13:48.674953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ✂️ Tokenization","metadata":{"id":"hVPv8uq4t4yA"}},{"cell_type":"code","source":"seq_len = 256 #max([len(text) for text in train['text']]) #256\nbatch_size = 16 #16\nnum_samples = len(train)\n\nmodel_name = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\ntokenizer = transformers.AutoTokenizer.from_pretrained(model_name)\n\ntrain_tokens = tokenizer(\n    train['text'].tolist(), \n    max_length=seq_len, \n    truncation=True, \n    padding='max_length', \n    add_special_tokens=True, \n    return_tensors='np'\n)\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain['target'] = le.fit_transform(train['target'])\ntest['target'] = le.fit_transform(test['target'])\n\ny_train = train['target'].values\nlabels = np.zeros((num_samples, y_train.max() + 1))\nlabels[np.arange(num_samples), y_train] = 1\n\ndataset = tf.data.Dataset.from_tensor_slices(\n    (\n        train_tokens['input_ids'], \n        train_tokens['attention_mask'], \n        labels\n    )\n)\n\ndef map_func(input_ids, masks, labels):\n    return {\n        'input_ids': input_ids,\n        'attention_mask': masks\n    }, labels\n\ndataset = dataset.map(map_func)\ndataset = dataset.shuffle(10000).batch(batch_size=batch_size, drop_remainder=True)\n\nsplit = 0.7\nsize = int((train_tokens['input_ids'].shape[0] // batch_size) * split)\n\ntrain_ds = dataset.take(size)\nval_ds = dataset.skip(size)","metadata":{"id":"uUmiRiaZt4yA","outputId":"3a3f1e1c-46f3-4808-9cdb-f38430e8ce30","execution":{"iopub.status.busy":"2023-05-16T20:13:48.677188Z","iopub.execute_input":"2023-05-16T20:13:48.677523Z","iopub.status.idle":"2023-05-16T20:14:16.716032Z","shell.execute_reply.started":"2023-05-16T20:13:48.677495Z","shell.execute_reply":"2023-05-16T20:14:16.715090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"size","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:14:16.719074Z","iopub.execute_input":"2023-05-16T20:14:16.719567Z","iopub.status.idle":"2023-05-16T20:14:16.724691Z","shell.execute_reply.started":"2023-05-16T20:14:16.719538Z","shell.execute_reply":"2023-05-16T20:14:16.723912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels.shape","metadata":{"id":"VOHSrQ0ow7JH","outputId":"2f8ecdb9-4ce6-44ff-e456-7d1c80e1940f","execution":{"iopub.status.busy":"2023-05-16T20:14:16.725697Z","iopub.execute_input":"2023-05-16T20:14:16.726061Z","iopub.status.idle":"2023-05-16T20:14:16.740599Z","shell.execute_reply.started":"2023-05-16T20:14:16.726035Z","shell.execute_reply":"2023-05-16T20:14:16.739638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🤖 Model Building","metadata":{"id":"90WNnnd4t4yA"}},{"cell_type":"code","source":"####### MODEL 3 #########\n'''\nIn this example, a BiLSTM layer is added after the Transformer layer. The number of units in the BiLSTM layer is set to 64, \nbut you can modify this value based on your specific use case. The output of the BiLSTM layer is passed through two dense layers, \neach with 512 units and a ReLU activation function, before being fed to the classifier head.\n'''\n\n# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n# instantiating the model in the strategy scope creates the model on the TPU\nwith tpu_strategy.scope():\n    model_name = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n    bert_model = TFAutoModel.from_pretrained(model_name)\n\n    # Input layers\n    input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n    mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n\n    # Transformer\n    embeddings = bert_model(input_ids, attention_mask=mask)[0]\n    embeddings = tf.keras.layers.GlobalAveragePooling1D()(embeddings)\n    embeddings = tf.keras.layers.Reshape((1, -1))(embeddings)\n\n    # Add a BiLSTM layer\n    lstm_units = 512 \n    lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, return_sequences=True))(embeddings)\n    attention_layer = tf.keras.layers.Attention()([lstm, lstm])\n\n    # Add Dense layers\n    #x = tf.keras.layers.Dense(512, activation='relu')(lstm)\n    x = tf.keras.layers.Dense(512, activation='relu')(attention_layer)\n    x = tf.keras.layers.Dense(256, activation='relu')(x)\n    x = tf.keras.layers.Dense(128, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.05)(x)\n\n    # Flatten the output tensor\n    x = tf.keras.layers.Flatten()(x)\n\n    # Classifier head\n    outputs = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(x)\n\n    # Create the model\n    model = tf.keras.Model(inputs=[input_ids, mask], outputs=outputs)\n\n    # Compile the model\n    learning_rate = 4e-5 # 4e-5\n    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n    loss = tf.keras.losses.CategoricalCrossentropy()\n    acc = tf.keras.metrics.CategoricalAccuracy()\n    model.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n\n'''\nIn the above example, monitor specifies the metric to be monitored for early stopping, \npatience specifies the number of epochs with no improvement after which training will be stopped, \nmode specifies whether the monitored metric should be minimized or maximized, and \nrestore_best_weights specifies whether to restore the weights of the model corresponding to the epoch with the best monitored metric value.\n\nAdagrad\nAdadelta\nRMSprop\n\n1.2277e-05 (best val loss)\n\n\nimport math\n# Define the LearningRateScheduler callback\ninitial_learning_rate = 1e-3\ndef lr_exp_decay(epoch):\n    k = 0.1\n    return initial_learning_rate * math.exp(-k*epoch)\n\n'''\n\nfilepath = \"model.h5\"\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]\n# Define early stopping\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n#lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_exp_decay)\n\n# Fit the model with early stopping\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs= 50,\n    batch_size=batch_size,\n    callbacks=[early_stop, callbacks_list]\n    #callbacks=[lr_callback] #\n)","metadata":{"_kg_hide-output":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-05-16T20:14:16.741665Z","iopub.execute_input":"2023-05-16T20:14:16.742205Z","iopub.status.idle":"2023-05-16T20:17:45.188164Z","shell.execute_reply.started":"2023-05-16T20:14:16.742179Z","shell.execute_reply":"2023-05-16T20:17:45.187021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working/model.h5","metadata":{"execution":{"iopub.status.busy":"2023-05-07T20:49:55.391087Z","iopub.execute_input":"2023-05-07T20:49:55.391738Z","iopub.status.idle":"2023-05-07T20:51:09.819730Z","shell.execute_reply.started":"2023-05-07T20:49:55.391699Z","shell.execute_reply":"2023-05-07T20:51:09.818476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n###### MODEL 1 ####\n\nmodel = TFAutoModel.from_pretrained(model_name)\n\n# Two inputs\ninput_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\nmask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n\n# Transformer\n# embeddings = model.bert(input_ids, attention_mask=mask)[1]\nembeddings = model(input_ids, attention_mask=mask)[0]\nembeddings = embeddings[:, 0, :]\n#embeddings = tf.keras.layers.GlobalAveragePooling1D()(embeddings)\n\n# Classifier head\nx = tf.keras.layers.Dense(512, activation='relu')(embeddings)\n#x = tf.keras.layers.Dropout(0.1)(x)\ny = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(x)\n\nbert_model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n\n# freeze bert layers\n# bert_model.layers[2].trainable = False\n\noptimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\nloss = tf.keras.losses.CategoricalCrossentropy()\nacc = tf.keras.metrics.CategoricalAccuracy()\n\nbert_model.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n\n# Define early stopping\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n\n# Fit the model with early stopping\nhistory = bert_model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=50,\n    batch_size=batch_size,\n    callbacks=[early_stop]\n)\n'''","metadata":{"_kg_hide-output":true,"id":"G_6t9Fc7t4yB","outputId":"5b1608cd-853f-4be5-dbc7-33784640e175","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n\n### MODEL 2 ####\nmodel = TFAutoModel.from_pretrained(model_name)\n\n# Two inputs\ninput_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\nmask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n\n# Transformer\nembeddings = model(input_ids, attention_mask=mask)[0]\nembeddings = tf.keras.layers.GlobalAveragePooling1D()(embeddings)\n#embeddings = embeddings[:, 0, :]\n\n# Classifier head\nx = tf.keras.layers.Dense(512, activation='relu')(embeddings)\nx = tf.keras.layers.Dense(256, activation='relu')(x)\nx = tf.keras.layers.Dense(128, activation='relu')(x)\nx = tf.keras.layers.Dropout(0.05)(x)\ny = tf.keras.layers.Dense(3, activation='softmax', name='outputs')(x)\n\n\nbert_model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate= 4e-5)\nloss = tf.keras.losses.CategoricalCrossentropy()\nacc = tf.keras.metrics.CategoricalAccuracy()\n\nbert_model.compile(optimizer=optimizer, loss=loss, metrics=[acc])\n\n# Define early stopping\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n\n# Fit the model with early stopping\nhistory = bert_model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=50,\n    batch_size=batch_size,\n    callbacks=[early_stop]\n)\n'''","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LIME Explainer","metadata":{}},{"cell_type":"code","source":"# 0 -> Neg, 1 -> Neu, 2 -> Pos\ntest3 = test[test['target']==0]","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:17:45.191154Z","iopub.execute_input":"2023-05-16T20:17:45.191580Z","iopub.status.idle":"2023-05-16T20:17:45.197823Z","shell.execute_reply.started":"2023-05-16T20:17:45.191549Z","shell.execute_reply":"2023-05-16T20:17:45.196839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for ind, (i, row) in enumerate(test3.iterrows()):\n    print(ind, row['text'])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-16T20:17:45.198928Z","iopub.execute_input":"2023-05-16T20:17:45.199234Z","iopub.status.idle":"2023-05-16T20:17:45.337633Z","shell.execute_reply.started":"2023-05-16T20:17:45.199207Z","shell.execute_reply":"2023-05-16T20:17:45.336693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 13\n\ndef prep_data(text):\n    tokens = tokenizer(\n        text, max_length=seq_len, truncation=True, \n        padding='max_length', \n        add_special_tokens=True, \n        return_tensors='tf'\n    )\n    return {\n        'input_ids': tokens['input_ids'], \n        'attention_mask': tokens['attention_mask']\n    }\n\nfor ind, (i, row) in enumerate(test3.iterrows()):\n    if ind == idx:\n        print(row.text)\n        tokens = prep_data(row['text'])\n\n# We choose a sample from test set\n\ntest_text = np.array(test3['text'])\ntest_class = np.array(test3['target'])\ntext_sample = test_text[idx]\nclass_names = ['Negative','Neutral','Positive']\nprint('Probability =', model.predict(tokens).round(3))\nprint('True class: %s' % class_names[test_class[idx]])","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:17:45.338742Z","iopub.execute_input":"2023-05-16T20:17:45.339044Z","iopub.status.idle":"2023-05-16T20:17:58.014898Z","shell.execute_reply.started":"2023-05-16T20:17:45.339017Z","shell.execute_reply":"2023-05-16T20:17:58.013660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_fn(x):    \n    x =  prep_data(x)\n    return model.predict(x)\n\nprint(text_sample)\nprint('Probability =', model.predict(tokens).round(3))\nprint('True class: %s' % class_names[test_class[idx]])\n\nfrom lime.lime_text import LimeTextExplainer\nexplainer = LimeTextExplainer(class_names=class_names)\nexp = explainer.explain_instance(text_sample, predict_fn, num_features=12, top_labels=3)\nexp.show_in_notebook(text=text_sample)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:17:58.016232Z","iopub.execute_input":"2023-05-16T20:17:58.016685Z","iopub.status.idle":"2023-05-16T20:18:09.802912Z","shell.execute_reply.started":"2023-05-16T20:17:58.016652Z","shell.execute_reply":"2023-05-16T20:18:09.801371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SHAP Explainer","metadata":{}},{"cell_type":"code","source":"test3 = test[test['target']==2]\nfor ind, (i, row) in enumerate(test3.iterrows()):\n    print(ind, row['text'])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-16T20:18:09.804565Z","iopub.execute_input":"2023-05-16T20:18:09.805738Z","iopub.status.idle":"2023-05-16T20:18:10.074226Z","shell.execute_reply.started":"2023-05-16T20:18:09.805690Z","shell.execute_reply":"2023-05-16T20:18:10.073004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test3[21:29] negative\n#test3[47:54] neutral\ntest3[19:26] # positive","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:18:10.075585Z","iopub.execute_input":"2023-05-16T20:18:10.075934Z","iopub.status.idle":"2023-05-16T20:18:10.325485Z","shell.execute_reply.started":"2023-05-16T20:18:10.075903Z","shell.execute_reply":"2023-05-16T20:18:10.324147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap \nimport scipy.special\n\ndef predictor(x):\n    input_ids = tokenizer(x, max_length=seq_len, truncation=True, padding='max_length', add_special_tokens=True, return_tensors='tf')['input_ids']\n    attention_mask = tokenizer(x, max_length=seq_len, truncation=True, padding='max_length', add_special_tokens=True, return_tensors='tf')['attention_mask']\n    outputs = model.predict([input_ids, attention_mask])\n    probas = tf.nn.softmax(outputs).numpy()\n    val = scipy.special.logit(probas[:,1])\n    return val\n\ndef f_batch(x):\n    val = np.array([])\n    for i in x:\n        val = np.append(val, predictor(i))\n    return val\n\nexplainer_roberta = shap.Explainer(f_batch, tokenizer)\n\nshap_values = explainer_roberta(test3['text'][19:26].tolist())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-16T20:18:10.329427Z","iopub.execute_input":"2023-05-16T20:18:10.329797Z","iopub.status.idle":"2023-05-16T20:51:43.229751Z","shell.execute_reply.started":"2023-05-16T20:18:10.329766Z","shell.execute_reply":"2023-05-16T20:51:43.226207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.plots.text(shap_values)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:51:52.147932Z","iopub.execute_input":"2023-05-16T20:51:52.148831Z","iopub.status.idle":"2023-05-16T20:51:52.811013Z","shell.execute_reply.started":"2023-05-16T20:51:52.148793Z","shell.execute_reply":"2023-05-16T20:51:52.809176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nshap.plots.bar(shap_values.mean(0))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:51:43.232700Z","iopub.status.idle":"2023-05-16T20:51:43.233046Z","shell.execute_reply.started":"2023-05-16T20:51:43.232870Z","shell.execute_reply":"2023-05-16T20:51:43.232886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can sort the bar chart in decending order\nshap.plots.bar(shap_values.mean(0), order=shap.Explanation.argsort)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:51:43.234308Z","iopub.status.idle":"2023-05-16T20:51:43.234639Z","shell.execute_reply.started":"2023-05-16T20:51:43.234477Z","shell.execute_reply":"2023-05-16T20:51:43.234492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ...or acending order\nshap.plots.bar(shap_values.mean(0), order=shap.Explanation.argsort.flip)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:51:43.235661Z","iopub.status.idle":"2023-05-16T20:51:43.236000Z","shell.execute_reply.started":"2023-05-16T20:51:43.235826Z","shell.execute_reply":"2023-05-16T20:51:43.235841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"'''\nimport matplotlib.pyplot as plt\n\n# Plot the learning rate schedule\nplt.figure(figsize=(8, 6))\nlrs = [lr_exp_decay(epoch) for epoch in range(50)]\nplt.plot(lrs, '-o', label='Exponential decay\\n1e-3 * e^(-0.1*epoch)')\nplt.title('Learning Rate vs Epoch')\nplt.xlabel('Epoch')  ## Epoch vs Learning rate\nplt.ylabel('Learning Rate')\nplt.legend()\nplt.savefig('lr_vs_epoch.png')\n\n# Plot the loss versus learning rate\nplt.figure(figsize=(8, 6))\nplt.plot(lrs, history.history['val_loss'], '-o', label='Exponential decay\\n1e-3 * e^(-0.1*epoch)')\nplt.xscale('log')\nplt.xlabel('Learning Rate (log)')\nplt.ylabel('Validation Loss')\nplt.legend()\nplt.title('Validation Loss vs Learning Rate')\nplt.savefig('val_loss_vs_lr.png')\n\n# Plot the loss versus learning rate\nplt.figure(figsize=(8, 6))\nplt.plot(lrs, history.history['loss'], '-o', label='Exponential decay\\n1e-3 * e^(-0.1*epoch)')\nplt.xscale('log')\nplt.xlabel('Learning Rate (log)')\nplt.ylabel('Training Loss')\nplt.legend()\nplt.title('Training Loss vs Learning Rate')\nplt.savefig('train_loss_vs_lr.png')\n\n# Plot the accuracy versus learning rate\nplt.figure(figsize=(8, 6))\nplt.plot(lrs, history.history['categorical_accuracy'], '-o', label='Exponential decay\\n1e-3 * e^(-0.1*epoch)')\nplt.xscale('log')\nplt.xlabel('Learning Rate (log)')\nplt.ylabel('Training Accuracy')\nplt.legend()\nplt.title('Training Accuracy vs Learning Rate')\nplt.savefig('train_acc_vs_lr.png')\n\n# Plot the accuracy versus learning rate\nplt.figure(figsize=(8, 6))\nplt.plot(lrs, history.history['val_categorical_accuracy'], '-o', label='Exponential decay\\n1e-3 * e^(-0.1*epoch)')\nplt.xscale('log')\nplt.xlabel('Learning Rate (log)')\nplt.ylabel('Validation Accuracy')\nplt.legend()\nplt.title('Validation Accuracy vs Learning Rate')\nplt.savefig('val_acc_vs_lr.png')\n'''","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# Find the best learning rate based on the validation loss\nval_losses = history.history['val_loss']\nbest_lr_idx = val_losses.index(min(val_losses))\nbest_lr = lr_exp_decay(best_lr_idx)\nprint('Best Learning Rate:', best_lr)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model = model","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:52:02.991461Z","iopub.execute_input":"2023-05-16T20:52:02.992427Z","iopub.status.idle":"2023-05-16T20:52:02.996494Z","shell.execute_reply.started":"2023-05-16T20:52:02.992387Z","shell.execute_reply":"2023-05-16T20:52:02.995390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:52:03.285837Z","iopub.execute_input":"2023-05-16T20:52:03.286485Z","iopub.status.idle":"2023-05-16T20:52:03.344360Z","shell.execute_reply.started":"2023-05-16T20:52:03.286456Z","shell.execute_reply":"2023-05-16T20:52:03.343266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 📊 Model Evaluation","metadata":{"id":"8EZ3MMzLt4yB"}},{"cell_type":"code","source":"# For Data Visualization\n!pip install plotly wordcloud\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport seaborn as sns\nimport wordcloud\n\n# Miscellaneous\nfrom tqdm import tqdm\nimport os\nimport random\nfrom IPython import display","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:04:00.382566Z","iopub.status.idle":"2023-05-16T21:04:00.382951Z","shell.execute_reply.started":"2023-05-16T21:04:00.382758Z","shell.execute_reply":"2023-05-16T21:04:00.382776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_learning_evolution(r):\n    plt.figure(figsize=(8, 6))\n    \n    #plt.subplot(2, 2, 1)\n    plt.plot(r.history['loss'], label='Loss')\n    plt.plot(r.history['val_loss'], label='val_Loss')\n    plt.title('Loss evolution during training')\n    plt.legend()\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.savefig('loss1.png')\n    \n    plt.figure(figsize=(8, 6))\n    #plt.subplot(2, 2, 2)\n    plt.plot(r.history['categorical_accuracy'], label='categorical_accuracy')\n    plt.plot(r.history['val_categorical_accuracy'], label='val_categorical_accuracy')\n    plt.title('Accuracy score evolution during training')\n    plt.legend()\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.savefig('accuracy1.png')","metadata":{"id":"Rk3PcAlht4yB","execution":{"iopub.status.busy":"2023-05-16T20:53:53.496740Z","iopub.execute_input":"2023-05-16T20:53:53.497136Z","iopub.status.idle":"2023-05-16T20:53:53.506803Z","shell.execute_reply.started":"2023-05-16T20:53:53.497107Z","shell.execute_reply":"2023-05-16T20:53:53.505691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_learning_evolution(history)","metadata":{"id":"ZjZMZexDt4yB","execution":{"iopub.status.busy":"2023-05-16T20:53:53.524015Z","iopub.execute_input":"2023-05-16T20:53:53.524305Z","iopub.status.idle":"2023-05-16T20:53:54.372821Z","shell.execute_reply.started":"2023-05-16T20:53:53.524263Z","shell.execute_reply":"2023-05-16T20:53:54.371549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model.evaluate(val_ds)","metadata":{"id":"Gquuud80t4yC","execution":{"iopub.status.busy":"2023-05-16T20:53:54.374506Z","iopub.execute_input":"2023-05-16T20:53:54.374805Z","iopub.status.idle":"2023-05-16T20:54:03.056601Z","shell.execute_reply.started":"2023-05-16T20:53:54.374779Z","shell.execute_reply":"2023-05-16T20:54:03.055305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert_model.evaluate(train_ds)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:54:03.057950Z","iopub.execute_input":"2023-05-16T20:54:03.058657Z","iopub.status.idle":"2023-05-16T20:54:20.366895Z","shell.execute_reply.started":"2023-05-16T20:54:03.058622Z","shell.execute_reply":"2023-05-16T20:54:20.365581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prep_data(text):\n    tokens = tokenizer(\n        text, max_length=seq_len, truncation=True, \n        padding='max_length', \n        add_special_tokens=True, \n        return_tensors='tf'\n    )\n    return {\n        'input_ids': tokens['input_ids'], \n        'attention_mask': tokens['attention_mask']\n    }\n\ntest['prediction'] = None\n\nfor i, row in test.iterrows():\n    tokens = prep_data(row['text'])\n    #probs = bert_model.predict(tokens)\n    probs = bert_model.predict_on_batch(tokens)\n    pred = np.argmax(probs)\n    test.at[i, 'prediction'] = pred\n    \ntest['prediction'] = test['prediction'].astype(int)\ntest","metadata":{"id":"hbI25MO7t4yC","execution":{"iopub.status.busy":"2023-05-16T20:54:20.369111Z","iopub.execute_input":"2023-05-16T20:54:20.369451Z","iopub.status.idle":"2023-05-16T21:04:00.375938Z","shell.execute_reply.started":"2023-05-16T20:54:20.369422Z","shell.execute_reply":"2023-05-16T21:04:00.373870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Negative','Neutral','Positive']\nfrom sklearn.metrics import classification_report\nprint(classification_report(test['target'], test['prediction'], target_names=labels))","metadata":{"id":"zkqzi2ys7EkP","execution":{"iopub.status.busy":"2023-05-16T21:04:00.377478Z","iopub.status.idle":"2023-05-16T21:04:00.377857Z","shell.execute_reply.started":"2023-05-16T21:04:00.377667Z","shell.execute_reply":"2023-05-16T21:04:00.377684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"id":"NjRdQm4Ot4yC","execution":{"iopub.status.busy":"2023-05-16T21:04:00.378972Z","iopub.status.idle":"2023-05-16T21:04:00.379318Z","shell.execute_reply.started":"2023-05-16T21:04:00.379138Z","shell.execute_reply":"2023-05-16T21:04:00.379153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.target.value_counts()","metadata":{"id":"7lLf3B45t4yC","execution":{"iopub.status.busy":"2023-05-16T20:51:43.253249Z","iopub.status.idle":"2023-05-16T20:51:43.253597Z","shell.execute_reply.started":"2023-05-16T20:51:43.253430Z","shell.execute_reply":"2023-05-16T20:51:43.253447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import *\ncm = confusion_matrix(test['target'], test['prediction'])\n\nplt.figure(figsize=(7,5))\n\nax = sns.heatmap(cm/np.sum(cm),fmt='.2%', annot=True, cmap='Blues')\n\nax.set_xlabel('\\nPredicted Values')\nax.set_ylabel('Actual Values\\n');\n\nax.xaxis.set_ticklabels(labels)\nax.yaxis.set_ticklabels(labels)\n\nplt.savefig('cm.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T21:04:00.384628Z","iopub.status.idle":"2023-05-16T21:04:00.384975Z","shell.execute_reply.started":"2023-05-16T21:04:00.384797Z","shell.execute_reply":"2023-05-16T21:04:00.384813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\ndef plot_classification_report(report):\n    report_data = []\n    lines = report.split('\\n')\n    lines = list(filter(None, lines))\n    for line in lines[1:-3]:\n        row = {}\n        row_data = line.split()\n        row_data = list(filter(None, row_data))\n        row['class'] = row_data[0]\n        row['precision'] = float(row_data[1])\n        row['recall'] = float(row_data[2])\n        row['f1_score'] = float(row_data[3])\n        row['support'] = float(row_data[4])\n        report_data.append(row)\n    df = pd.DataFrame.from_dict(report_data)\n    df.set_index('class', inplace=True)\n    heatmap = sns.heatmap(df, annot=True, cmap='Reds', fmt='.2f')\n    heatmap.set_xlabel('\\nMetrics')\n    heatmap.set_ylabel('Class\\n')\n    heatmap.set_title('Classification Report')\n\n\ndef accuracy_score(report):\n    report_data = []\n    lines = report.split('\\n')\n    lines = list(filter(None, lines))\n    for line in lines[4:-2]:\n        row_data = line.split()\n        row_data = list(filter(None, row_data))\n        return float(row_data[1])\n\n\nlabels = ['Negative','Neutral','Positive']\n\nreport = classification_report(test['target'], test['prediction'], target_names=labels)\nplot_classification_report(report)\naccuracy = accuracy_score(report)\n\nplt.title('Measure\\nAccuracy: {:.2f}%'.format(accuracy*100))\nplt.savefig('classification_reports.png')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:51:43.256190Z","iopub.status.idle":"2023-05-16T20:51:43.256533Z","shell.execute_reply.started":"2023-05-16T20:51:43.256368Z","shell.execute_reply":"2023-05-16T20:51:43.256384Z"},"trusted":true},"execution_count":null,"outputs":[]}]}