ğŸ“ nlp-roBERTa-biLSTM-attention
â””â”€â”€ ğŸ“ BERT
    ğŸ“ nlp-roBERTa-biLSTM-attention\BERT
    â”œâ”€â”€ ğŸ“„ all_models1.png
    â”œâ”€â”€ ğŸ“„ all_models2.png
    â”œâ”€â”€ ğŸ“„ all_models3.png
    â”œâ”€â”€ ğŸ“„ all_models4.png
    â”œâ”€â”€ ğŸ“„ lgb_knn_mlp.png
    â”œâ”€â”€ ğŸ“„ rf_knn_mlp.png
â””â”€â”€ ğŸ“ BoW
    ğŸ“ nlp-roBERTa-biLSTM-attention\BoW
    â”œâ”€â”€ ğŸ“„ all_models_1.png
    â”œâ”€â”€ ğŸ“„ all_models_2.png
    â”œâ”€â”€ ğŸ“„ all_models_3.png
    â”œâ”€â”€ ğŸ“„ all_models_4.png
    â”œâ”€â”€ ğŸ“„ dask_xgb.png
    â”œâ”€â”€ ğŸ“„ rf_bagging.png
    â”œâ”€â”€ ğŸ“„ rf_gb_voting.png
    â”œâ”€â”€ ğŸ“„ rf_knn_mlp.png
â””â”€â”€ ğŸ“ Data_scraping
    ğŸ“ nlp-roBERTa-biLSTM-attention\Data_scraping
    â”œâ”€â”€ ğŸ“„ Twint-data collection.ipynb
    â”œâ”€â”€ ğŸ“„ Twitter academic api.ipynb
â””â”€â”€ ğŸ“ Extended_datasets
    ğŸ“ nlp-roBERTa-biLSTM-attention\Extended_datasets
    â”œâ”€â”€ ğŸ“ Global_covid_twitter_data
    â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\Extended_datasets\Global_covid_twitter_data
    â”‚   â”œâ”€â”€ ğŸ“„ Global.csv
    â”‚   â”œâ”€â”€ ğŸ“„ Global_twitter_data_preprocessing.ipynb
    â”‚   â”œâ”€â”€ ğŸ“„ best-model-global.ipynb
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report1.png
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report2.png
    â”‚   â”œâ”€â”€ ğŸ“„ confusion_matrix.png
    â”‚   â”œâ”€â”€ ğŸ“ preprocessed_dataset
    â”‚   â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\Extended_datasets\Global_covid_twitter_data\preprocessed_dataset
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_0.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_1.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_10.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_11.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_12.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_13.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_14.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_15.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_16.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_17.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_18.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_19.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_2.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_20.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_21.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_22.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_23.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_24.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_25.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_26.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_27.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_28.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_29.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_3.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_30.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_31.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_32.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_33.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_34.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_35.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_36.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_37.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_38.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_39.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_4.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_40.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_5.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_6.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_7.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_8.csv
    â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sample_data_global_9.csv
    â”‚   â”œâ”€â”€ ğŸ“„ tweets_distribution_global.png
    â”‚   â”œâ”€â”€ ğŸ“„ word_cloud_global.png
    â”‚   â”œâ”€â”€ ğŸ“„ word_freq.png
    â”œâ”€â”€ ğŸ“ Only_USA_covid_twitter_data
    â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\Extended_datasets\Only_USA_covid_twitter_data
    â”‚   â””â”€â”€ ğŸ“„ Only_USA.csv
    â”‚   â””â”€â”€ ğŸ“„ frequency.png
    â”‚   â””â”€â”€ ğŸ“ model3_attention
    â”‚       ğŸ“ nlp-roBERTa-biLSTM-attention\Extended_datasets\Only_USA_covid_twitter_data\model3_attention
    â”‚       â”œâ”€â”€ ğŸ“„ accuracy.png
    â”‚       â”œâ”€â”€ ğŸ“„ best-model-only-usa.ipynb
    â”‚       â”œâ”€â”€ ğŸ“„ classification_report1.png
    â”‚       â”œâ”€â”€ ğŸ“„ classification_reports.png
    â”‚       â”œâ”€â”€ ğŸ“„ confusion_matrix.png
    â”‚       â”œâ”€â”€ ğŸ“„ loss.png
    â”‚       â”œâ”€â”€ ğŸ“„ model_architecture.png
    â”‚   â””â”€â”€ ğŸ“„ only_USA_twitter_data_preprocessing.ipynb
    â”‚   â””â”€â”€ ğŸ“„ sample_data_only_USA.csv
    â”‚   â””â”€â”€ ğŸ“„ uk_covid_twitter_sentiment.ipynb
    â”‚   â””â”€â”€ ğŸ“„ word_cloud.png
â””â”€â”€ ğŸ“ External_datasets
    ğŸ“ nlp-roBERTa-biLSTM-attention\External_datasets
    â”œâ”€â”€ ğŸ“ Apple_twitter_sentiments
    â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\External_datasets\Apple_twitter_sentiments
    â”‚   â”œâ”€â”€ ğŸ“„ accuracy.png
    â”‚   â”œâ”€â”€ ğŸ“„ best-model-apple-twitter.ipynb
    â”‚   â”œâ”€â”€ ğŸ“„ classification_reports1.png
    â”‚   â”œâ”€â”€ ğŸ“„ classification_reports2.png
    â”‚   â”œâ”€â”€ ğŸ“„ confusion_matrix.png
    â”‚   â”œâ”€â”€ ğŸ“„ loss.png
    â”œâ”€â”€ ğŸ“ Reddit
    â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\External_datasets\Reddit
    â”‚   â”œâ”€â”€ ğŸ“„ Reddit_Data.csv
    â”‚   â”œâ”€â”€ ğŸ“„ Screenshot 2023-05-08 025117.png
    â”‚   â”œâ”€â”€ ğŸ“„ Screenshot 2023-05-08 025141.png
    â”‚   â”œâ”€â”€ ğŸ“„ Screenshot 2023-05-08 025820.png
    â”‚   â”œâ”€â”€ ğŸ“„ Screenshot 2023-05-08 025915.png
    â”‚   â”œâ”€â”€ ğŸ“„ Screenshot 2023-05-08 025934.png
    â”‚   â”œâ”€â”€ ğŸ“„ Screenshot 2023-05-08 025955.png
    â”‚   â”œâ”€â”€ ğŸ“„ Screenshot 2023-05-08 030042.png
    â”‚   â”œâ”€â”€ ğŸ“„ best-model-reddit.ipynb
    â”‚   â”œâ”€â”€ ğŸ“„ classification_reports.png
    â”‚   â”œâ”€â”€ ğŸ“„ cm.png
    â”œâ”€â”€ ğŸ“ Twitter
    â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\External_datasets\Twitter
    â”‚   â”œâ”€â”€ ğŸ“„ Twitter_Data.csv
    â”‚   â”œâ”€â”€ ğŸ“„ best-model-twitter-external.ipynb
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report1.png
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report2.png
    â”‚   â”œâ”€â”€ ğŸ“„ confusion_matrix.png
    â”œâ”€â”€ ğŸ“ US_airlines_twitter_sentiments
    â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\External_datasets\US_airlines_twitter_sentiments
    â”‚   â”œâ”€â”€ ğŸ“„ accuracy.png
    â”‚   â”œâ”€â”€ ğŸ“„ best-model-us-airlines.ipynb
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report1.png
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report2.png
    â”‚   â”œâ”€â”€ ğŸ“„ confusion_matrix.png
    â”‚   â”œâ”€â”€ ğŸ“„ loss.png
    â”œâ”€â”€ ğŸ“„ token.txt
â””â”€â”€ ğŸ“„ LICENSE
â””â”€â”€ ğŸ“ Previous_research
    ğŸ“ nlp-roBERTa-biLSTM-attention\Previous_research
    â”œâ”€â”€ ğŸ“„ 1.png
    â”œâ”€â”€ ğŸ“„ 2.png
    â”œâ”€â”€ ğŸ“„ Vaibhav 2022.pdf
    â”œâ”€â”€ ğŸ“„ Yuxing 2023.pdf
â””â”€â”€ ğŸ“„ README.md
â””â”€â”€ ğŸ“ RoBERTa
    ğŸ“ nlp-roBERTa-biLSTM-attention\RoBERTa
    â”œâ”€â”€ ğŸ“„ cardiff_all_models_1.png
    â”œâ”€â”€ ğŸ“„ cardiff_all_models_2.png
    â”œâ”€â”€ ğŸ“„ cardiff_all_models_3.png
    â”œâ”€â”€ ğŸ“„ cardiff_all_models_4.png
    â”œâ”€â”€ ğŸ“„ lgb+knn+mlp.png
    â”œâ”€â”€ ğŸ“„ roberta_base_rf+knn+mlp.png
â””â”€â”€ ğŸ“ SBERT
    ğŸ“ nlp-roBERTa-biLSTM-attention\SBERT
    â”œâ”€â”€ ğŸ“„ all_models_1.png
    â”œâ”€â”€ ğŸ“„ all_models_2.png
    â”œâ”€â”€ ğŸ“„ all_models_3.png
    â”œâ”€â”€ ğŸ“„ all_models_4.png
    â”œâ”€â”€ ğŸ“„ all_models_5.png
    â”œâ”€â”€ ğŸ“„ lgb_knn_mlp.png
    â”œâ”€â”€ ğŸ“„ rf_knn_mlp.png
â””â”€â”€ ğŸ“ TF-IDF
    ğŸ“ nlp-roBERTa-biLSTM-attention\TF-IDF
    â”œâ”€â”€ ğŸ“„ all_models_1.png
    â”œâ”€â”€ ğŸ“„ all_models_2.png
    â”œâ”€â”€ ğŸ“„ all_models_3.png
    â”œâ”€â”€ ğŸ“„ all_models_4.png
    â”œâ”€â”€ ğŸ“„ rf_bagging.png
    â”œâ”€â”€ ğŸ“„ rf_knn_mlp.png
    â”œâ”€â”€ ğŸ“„ rf_stacking_voting.png
â””â”€â”€ ğŸ“ Target_lexicon_selection
    ğŸ“ nlp-roBERTa-biLSTM-attention\Target_lexicon_selection
    â”œâ”€â”€ ğŸ“„ target_lexicon_selection.ipynb
    â”œâ”€â”€ ğŸ“„ textblob1.png
    â”œâ”€â”€ ğŸ“„ textblob2.png
    â”œâ”€â”€ ğŸ“„ textblob3.png
    â”œâ”€â”€ ğŸ“„ textblob4.png
    â”œâ”€â”€ ğŸ“„ vader1.png
    â”œâ”€â”€ ğŸ“„ vader2.png
    â”œâ”€â”€ ğŸ“„ vader3.png
    â”œâ”€â”€ ğŸ“„ vader4.png
    â”œâ”€â”€ ğŸ“„ wordnet1.png
    â”œâ”€â”€ ğŸ“„ wordnet2.png
    â”œâ”€â”€ ğŸ“„ wordnet3.png
    â”œâ”€â”€ ğŸ“„ wordnet4.png
â””â”€â”€ ğŸ“ Twitter-RoBERTa+LSTM
    ğŸ“ nlp-roBERTa-biLSTM-attention\Twitter-RoBERTa+LSTM
    â”œâ”€â”€ ğŸ“ BiLSTM+CNN
    â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\Twitter-RoBERTa+LSTM\BiLSTM+CNN
    â”‚   â”œâ”€â”€ ğŸ“„ accuracy.png
    â”‚   â”œâ”€â”€ ğŸ“„ biLSTM+CNN.ipynb
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report.png
    â”‚   â”œâ”€â”€ ğŸ“„ confusion_matrix.png
    â”‚   â”œâ”€â”€ ğŸ“„ loss.png
    â”‚   â”œâ”€â”€ ğŸ“„ model_architecture.png
    â”œâ”€â”€ ğŸ“ model1_keras_1_dense_layers
    â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\Twitter-RoBERTa+LSTM\model1_keras_1_dense_layers
    â”‚   â”œâ”€â”€ ğŸ“„ Screenshot 2023-04-20 215305.png
    â”‚   â”œâ”€â”€ ğŸ“„ accuracy1.png
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report.png
    â”‚   â”œâ”€â”€ ğŸ“„ confusion_matrix.png
    â”‚   â”œâ”€â”€ ğŸ“„ loss1.png
    â”‚   â”œâ”€â”€ ğŸ“„ model_architecture.png
    â”‚   â”œâ”€â”€ ğŸ“„ summary.png
    â”œâ”€â”€ ğŸ“ model2_keras_3_dense_layers
    â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\Twitter-RoBERTa+LSTM\model2_keras_3_dense_layers
    â”‚   â”œâ”€â”€ ğŸ“„ accuracy1.png
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report.png
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report1.png
    â”‚   â”œâ”€â”€ ğŸ“„ confusion_matrix.png
    â”‚   â”œâ”€â”€ ğŸ“„ loss1.png
    â”‚   â”œâ”€â”€ ğŸ“„ model_architecture.png
    â”‚   â”œâ”€â”€ ğŸ“„ model_summary.png
    â”‚   â”œâ”€â”€ ğŸ“„ train_val_loss.png
    â”œâ”€â”€ ğŸ“ model3_BiLSTM
    â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\Twitter-RoBERTa+LSTM\model3_BiLSTM
    â”‚   â”œâ”€â”€ ğŸ“„ accuracy.png
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report1.png
    â”‚   â”œâ”€â”€ ğŸ“„ classification_report2.png
    â”‚   â”œâ”€â”€ ğŸ“„ confusion_matrix.png
    â”‚   â”œâ”€â”€ ğŸ“„ loss.png
    â”‚   â”œâ”€â”€ ğŸ“„ lr_vs_epoch.png
    â”‚   â”œâ”€â”€ ğŸ“„ model_architecture.png
    â”‚   â”œâ”€â”€ ğŸ“„ summary.png
    â”‚   â”œâ”€â”€ ğŸ“„ target_val_counts.png
    â”‚   â”œâ”€â”€ ğŸ“„ train_acc_vs_lr.png
    â”‚   â”œâ”€â”€ ğŸ“„ train_loss_vs_lr.png
    â”‚   â”œâ”€â”€ ğŸ“„ training_val.png
    â”‚   â”œâ”€â”€ ğŸ“„ val_acc_vs_lr.png
    â”‚   â”œâ”€â”€ ğŸ“„ val_loss_vs_lr.png
    â”œâ”€â”€ ğŸ“ model4_BiLSTM+attention
    â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\Twitter-RoBERTa+LSTM\model4_BiLSTM+attention
    â”‚   â””â”€â”€ ğŸ“ XAI
    â”‚       ğŸ“ nlp-roBERTa-biLSTM-attention\Twitter-RoBERTa+LSTM\model4_BiLSTM+attention\XAI
    â”‚       â”œâ”€â”€ ğŸ“ Lime
    â”‚       â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\Twitter-RoBERTa+LSTM\model4_BiLSTM+attention\XAI\Lime
    â”‚       â”‚   â”œâ”€â”€ ğŸ“„ lime1.png
    â”‚       â”‚   â”œâ”€â”€ ğŸ“„ lime2.png
    â”‚       â”‚   â”œâ”€â”€ ğŸ“„ lime3.png
    â”‚       â”‚   â”œâ”€â”€ ğŸ“„ lime4.png
    â”‚       â”‚   â”œâ”€â”€ ğŸ“„ lime5.png
    â”‚       â”‚   â”œâ”€â”€ ğŸ“„ lime6.png
    â”‚       â”‚   â”œâ”€â”€ ğŸ“„ lime7.png
    â”‚       â”œâ”€â”€ ğŸ“ SHAP
    â”‚       â”‚   ğŸ“ nlp-roBERTa-biLSTM-attention\Twitter-RoBERTa+LSTM\model4_BiLSTM+attention\XAI\SHAP
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_neg1.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_neg2.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_neg_bar_ascending.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_neg_bar_descending.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_neu1.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_neu2.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_neu_bar.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_neu_bar_ascending.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_neu_bar_descending.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_pos1.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_pos2.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_pos_bar_ascending.png
    â”‚       â”‚   â””â”€â”€ ğŸ“„ shap_pos_bar_descending.png
    â”‚   â””â”€â”€ ğŸ“„ learning_rates.png
    â”‚   â””â”€â”€ ğŸ“„ model_architecture.png
    â”‚   â””â”€â”€ ğŸ“„ summary.png
    â”‚   â””â”€â”€ ğŸ“ uk_twitter_data_3k
    â”‚       ğŸ“ nlp-roBERTa-biLSTM-attention\Twitter-RoBERTa+LSTM\model4_BiLSTM+attention\uk_twitter_data_3k
    â”‚       â”œâ”€â”€ ğŸ“„ accuracy.png
    â”‚       â”œâ”€â”€ ğŸ“„ best-model_uk-tweet_3k.ipynb
    â”‚       â”œâ”€â”€ ğŸ“„ classification_report.png
    â”‚       â”œâ”€â”€ ğŸ“„ classification_report2.png
    â”‚       â”œâ”€â”€ ğŸ“„ confusion_matrix.png
    â”‚       â”œâ”€â”€ ğŸ“„ loss.png
    â”‚       â”œâ”€â”€ ğŸ“„ train_val_loss.png
    â”‚   â””â”€â”€ ğŸ“ uk_twitter_data_all
    â”‚       ğŸ“ nlp-roBERTa-biLSTM-attention\Twitter-RoBERTa+LSTM\model4_BiLSTM+attention\uk_twitter_data_all
    â”‚       â””â”€â”€ ğŸ“„ accuracy.png
    â”‚       â””â”€â”€ ğŸ“„ best-model-uk-twitter-all.ipynb
    â”‚       â””â”€â”€ ğŸ“„ classification_report1.png
    â”‚       â””â”€â”€ ğŸ“„ classification_report2.png
    â”‚       â””â”€â”€ ğŸ“„ confusion_matrix.png
    â”‚       â””â”€â”€ ğŸ“„ loss.png
â””â”€â”€ ğŸ“ UK_covid_twitter_data
    ğŸ“ nlp-roBERTa-biLSTM-attention\UK_covid_twitter_data
    â”œâ”€â”€ ğŸ“„ all_cities.csv
    â”œâ”€â”€ ğŸ“„ sample_data_3000.csv
    â”œâ”€â”€ ğŸ“„ sample_data_all.csv
    â”œâ”€â”€ ğŸ“„ stacked bar graph.png
    â”œâ”€â”€ ğŸ“„ tweets distribution.png
    â”œâ”€â”€ ğŸ“„ uk_twitter_data_preprocessing.ipynb
â””â”€â”€ ğŸ“„ list.md
â””â”€â”€ ğŸ“„ uk-twitter-3k-classical-modelling.ipynb
â””â”€â”€ ğŸ“ word2vec
    ğŸ“ nlp-roBERTa-biLSTM-attention\word2vec
    â””â”€â”€ ğŸ“„ all_models_1.png
    â””â”€â”€ ğŸ“„ all_models_2.png
    â””â”€â”€ ğŸ“„ all_models_3.png
    â””â”€â”€ ğŸ“„ all_models_4.png
    â””â”€â”€ ğŸ“„ rf_knn_mlp.png
    â””â”€â”€ ğŸ“„ rf_stacking_voting.png